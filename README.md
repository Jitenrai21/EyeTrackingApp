# Eye Tracking Cursor Control Web App

This project is a full-stack implementation of a real-time eye-tracking web application that captures webcam input from the frontend and processes it using computer vision techniques on the backend to control the mouse cursor via gaze direction and wink detection.

## ğŸ” Features

- Real-time webcam frame capture using HTML5 and JavaScript
- Backend processing using Python (Flask + OpenCV)
- Eye landmark detection and gaze tracking
- Wink detection for left/right click simulation
- PyAutoGUI integration to control the system cursor
- Smooth frontend-backend integration with JSON API
- Responsive and accessible user interface

## ğŸ›  Tech Stack

- **Frontend**: HTML5, JavaScript, CSS
- **Backend**: Python, Flask, OpenCV
- **Computer Vision**: MediaPipe-based facial landmark detection
- **Mouse Control**: PyAutoGUI
- **Communication**: JSON over HTTP (Fetch API)

## ğŸš€ Project Structure
```
project/
â”‚
â”œâ”€â”€ static/ # Frontend JS script
â”‚ â””â”€â”€ script.js
â”‚
â”œâ”€â”€ templates/ # HTML template
â”‚ â””â”€â”€ index.html
â”‚
â”œâ”€â”€ modules/ # Detection and tracking logic
â”‚ â”œâ”€â”€ detector.py
â”‚ â”œâ”€â”€ gaze_tracker.py
â”‚ â”œâ”€â”€ wink_detector.py
â”‚ â””â”€â”€ controller.py
â”‚
â”œâ”€â”€ app.py # Flask application entry point
â””â”€â”€ README.md # Project documentation
```


## âš™ï¸ Setup Instructions

1. **Clone the repository**
```bash
git clone https://github.com/Jitenrai21/EyeTrackingApp
cd EyeTrackingApp
```
Install dependencies

```bash
pip install -r requirements.txt
```

Run the application
```bash
python -m web.app
```

Access the app
Open your browser and go to: http://localhost:5000

## ğŸ“¸ How It Works
- The frontend captures webcam frames using the HTML5 video API and sends them to the backend every 200ms.
- The backend decodes the image, detects facial landmarks, and estimates gaze direction and wink.
- Based on the estimation, the system cursor is moved or mouse clicks are triggered.

## ğŸ¯ Goals and Insights
- Understanding the integration between frontend and backend systems was key to making this project production-ready. It demonstrates how aligning real-time UI input with backend intelligence enables fluid, responsive applications.
